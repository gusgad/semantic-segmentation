{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules imported.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, Conv2DTranspose\n",
    "from keras.initializers import Constant\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import argparse\n",
    "import glob\n",
    "import copy\n",
    "import skimage\n",
    "from skimage import io\n",
    "import os\n",
    "\n",
    "print('Modules imported.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer conv2d_664 was called with an input that isn't a symbolic tensor. Received type: <class 'numpy.ndarray'>. Full input: [array([[[[125, 195, 255],\n         [124, 196, 255],\n         [127, 195, 255],\n         ..., \n         [  3,   4,   7],\n         [  1,   3,   7],\n         [  1,   3,   5]],\n\n        [[125, 190, 255],\n         [125, 191, 255],\n         [128, 194, 255],\n         ..., \n         [  2,   4,   7],\n         [  0,   3,   7],\n         [  1,   4,   5]],\n\n        [[125, 192, 255],\n         [124, 191, 255],\n         [127, 194, 255],\n         ..., \n         [  3,   5,   7],\n         [  2,   4,   7],\n         [  2,   3,   5]],\n\n        ..., \n        [[ 29,  29,  32],\n         [ 31,  29,  32],\n         [ 30,  28,  35],\n         ..., \n         [116, 107, 104],\n         [114, 100, 103],\n         [103, 101, 104]],\n\n        [[ 29,  29,  32],\n         [ 29,  29,  33],\n         [ 29,  29,  35],\n         ..., \n         [116, 105, 100],\n         [115, 100,  99],\n         [107,  98, 100]],\n\n        [[ 30,  28,  32],\n         [ 29,  30,  33],\n         [ 29,  30,  33],\n         ..., \n         [116, 108, 108],\n         [116, 104, 102],\n         [114, 102, 100]]],\n\n\n       [[[  5,   6,   4],\n         [  5,   6,   5],\n         [  6,   6,   5],\n         ..., \n         [ 12,  14,   6],\n         [ 14,  12,   8],\n         [ 12,  15,  14]],\n\n        [[  5,   6,   5],\n         [  5,   6,   5],\n         [  6,   7,   5],\n         ..., \n         [  8,  10,   7],\n         [  5,  11,   9],\n         [  5,  14,  11]],\n\n        [[  4,   6,   5],\n         [  4,   5,   5],\n         [  5,   6,   5],\n         ..., \n         [  9,  12,   8],\n         [  9,  13,   8],\n         [ 10,  13,   9]],\n\n        ..., \n        [[100,  83,  67],\n         [ 95,  82,  71],\n         [ 97,  85,  73],\n         ..., \n         [154, 147, 109],\n         [154, 146, 104],\n         [153, 145, 102]],\n\n        [[124,  90,  75],\n         [148,  91,  75],\n         [147, 110,  74],\n         ..., \n         [167, 164, 134],\n         [161, 163, 116],\n         [160, 156, 113]],\n\n        [[146,  94,  73],\n         [168, 102,  72],\n         [149, 118,  69],\n         ..., \n         [183, 158, 117],\n         [181, 156, 117],\n         [178, 154, 114]]],\n\n\n       [[[ 19,  19,  23],\n         [ 17,  18,  21],\n         [ 16,  18,  23],\n         ..., \n         [ 14,  11,  13],\n         [ 15,  10,  12],\n         [ 15,  10,  11]],\n\n        [[ 20,  21,  25],\n         [ 21,  20,  26],\n         [ 20,  19,  28],\n         ..., \n         [ 14,  10,   8],\n         [ 15,  11,   8],\n         [ 16,  11,   9]],\n\n        [[ 19,  23,  37],\n         [ 23,  23,  37],\n         [ 30,  24,  36],\n         ..., \n         [ 14,  11,  10],\n         [ 16,  11,  11],\n         [ 17,   9,  10]],\n\n        ..., \n        [[ 47,  91,  86],\n         [ 25,  66,  62],\n         [ 31,  41,  31],\n         ..., \n         [ 20,  21,  21],\n         [ 20,  22,  23],\n         [ 21,  22,  24]],\n\n        [[ 42,  84,  87],\n         [ 26,  59,  56],\n         [ 30,  37,  30],\n         ..., \n         [ 16,  20,  21],\n         [ 15,  22,  22],\n         [ 16,  23,  24]],\n\n        [[ 37,  74,  54],\n         [ 27,  48,  40],\n         [ 29,  31,  31],\n         ..., \n         [ 17,  19,  18],\n         [ 16,  20,  19],\n         [ 16,  22,  23]]],\n\n\n       ..., \n       [[[255, 255, 255],\n         [255, 255, 255],\n         [255, 255, 255],\n         ..., \n         [ 27,  32,  32],\n         [ 33,  40,  30],\n         [ 37,  37,  22]],\n\n        [[255, 255, 255],\n         [255, 255, 255],\n         [255, 255, 255],\n         ..., \n         [ 39,  55,  29],\n         [ 49,  51,  26],\n         [ 49,  35,  19]],\n\n        [[255, 255, 255],\n         [255, 255, 255],\n         [255, 255, 255],\n         ..., \n         [ 45,  56,  27],\n         [ 47,  49,  24],\n         [ 46,  39,  16]],\n\n        ..., \n        [[ 11,  12,  14],\n         [ 12,  12,  14],\n         [ 12,  12,  15],\n         ..., \n         [ 63,  59,  55],\n         [ 63,  60,  56],\n         [ 66,  62,  54]],\n\n        [[ 12,  13,  14],\n         [ 13,  12,  14],\n         [ 13,  12,  15],\n         ..., \n         [ 62,  60,  59],\n         [ 62,  63,  64],\n         [ 67,  67,  64]],\n\n        [[ 13,  11,  14],\n         [ 14,  11,  14],\n         [ 13,  11,  14],\n         ..., \n         [ 60,  63,  63],\n         [ 60,  67,  65],\n         [ 67,  70,  65]]],\n\n\n       [[[157, 254, 255],\n         [156, 254, 255],\n         [155, 255, 255],\n         ..., \n         [ 32,  27,  11],\n         [ 47,  29,  11],\n         [ 49,  26,  11]],\n\n        [[158, 255, 255],\n         [158, 255, 255],\n         [155, 255, 255],\n         ..., \n         [ 37,  34,  13],\n         [ 56,  34,  13],\n         [ 54,  26,  14]],\n\n        [[146, 236, 255],\n         [146, 239, 255],\n         [154, 240, 255],\n         ..., \n         [ 34,  29,  13],\n         [ 43,  31,  14],\n         [ 38,  26,  16]],\n\n        ..., \n        [[241, 228, 178],\n         [228, 232, 173],\n         [230, 222, 167],\n         ..., \n         [  5,   5,   5],\n         [  5,   5,   6],\n         [  3,   4,   6]],\n\n        [[250, 241, 182],\n         [254, 245, 181],\n         [251, 241, 175],\n         ..., \n         [  4,   4,   6],\n         [  5,   3,   5],\n         [  4,   4,   5]],\n\n        [[255, 226, 165],\n         [255, 221, 155],\n         [246, 214, 141],\n         ..., \n         [  4,   5,   6],\n         [  4,   4,   5],\n         [  4,   3,   5]]],\n\n\n       [[[ 75, 158, 155],\n         [ 90, 176, 202],\n         [113, 152, 223],\n         ..., \n         [114, 171, 248],\n         [114, 171, 249],\n         [113, 171, 251]],\n\n        [[ 62,  53,  60],\n         [ 55,  81,  89],\n         [108, 115, 102],\n         ..., \n         [114, 171, 248],\n         [111, 171, 247],\n         [111, 171, 245]],\n\n        [[ 71,  41,  52],\n         [ 71,  50,  61],\n         [ 68,  94,  51],\n         ..., \n         [115, 171, 247],\n         [114, 172, 245],\n         [115, 173, 240]],\n\n        ..., \n        [[ 83,  88,  90],\n         [ 86,  91,  89],\n         [ 86,  90,  83],\n         ..., \n         [ 95,  90,  96],\n         [ 94,  90,  97],\n         [ 90,  91,  98]],\n\n        [[ 82,  90,  97],\n         [ 83,  93,  91],\n         [ 82,  88,  81],\n         ..., \n         [ 96,  86,  88],\n         [ 96,  87,  88],\n         [ 92,  86,  88]],\n\n        [[ 82,  85,  93],\n         [ 82,  84,  91],\n         [ 82,  80,  88],\n         ..., \n         [ 96,  89,  89],\n         [ 96,  91,  89],\n         [ 92,  90,  89]]]], dtype=uint8)]. All inputs to the layer should be tensors.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/Programs/conda/envs/semantic-segmentation/lib/python3.5/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m                 \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_keras_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programs/conda/envs/semantic-segmentation/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mis_keras_tensor\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    402\u001b[0m                           tf.SparseTensor)):\n\u001b[0;32m--> 403\u001b[0;31m         raise ValueError('Unexpectedly found an instance of type `' + str(type(x)) + '`. '\n\u001b[0m\u001b[1;32m    404\u001b[0m                          'Expected a symbolic tensor instance.')\n",
      "\u001b[0;31mValueError\u001b[0m: Unexpectedly found an instance of type `<class 'numpy.ndarray'>`. Expected a symbolic tensor instance.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-da95225f1b7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m x = Conv2DTranspose(filters=2, \n\u001b[1;32m      7\u001b[0m                         \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programs/conda/envs/semantic-segmentation/lib/python3.5/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    556\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programs/conda/envs/semantic-segmentation/lib/python3.5/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    429\u001b[0m                                  \u001b[0;34m'Received type: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m                                  \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. Full input: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m                                  \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. All inputs to the layer '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m                                  'should be tensors.')\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Layer conv2d_664 was called with an input that isn't a symbolic tensor. Received type: <class 'numpy.ndarray'>. Full input: [array([[[[125, 195, 255],\n         [124, 196, 255],\n         [127, 195, 255],\n         ..., \n         [  3,   4,   7],\n         [  1,   3,   7],\n         [  1,   3,   5]],\n\n        [[125, 190, 255],\n         [125, 191, 255],\n         [128, 194, 255],\n         ..., \n         [  2,   4,   7],\n         [  0,   3,   7],\n         [  1,   4,   5]],\n\n        [[125, 192, 255],\n         [124, 191, 255],\n         [127, 194, 255],\n         ..., \n         [  3,   5,   7],\n         [  2,   4,   7],\n         [  2,   3,   5]],\n\n        ..., \n        [[ 29,  29,  32],\n         [ 31,  29,  32],\n         [ 30,  28,  35],\n         ..., \n         [116, 107, 104],\n         [114, 100, 103],\n         [103, 101, 104]],\n\n        [[ 29,  29,  32],\n         [ 29,  29,  33],\n         [ 29,  29,  35],\n         ..., \n         [116, 105, 100],\n         [115, 100,  99],\n         [107,  98, 100]],\n\n        [[ 30,  28,  32],\n         [ 29,  30,  33],\n         [ 29,  30,  33],\n         ..., \n         [116, 108, 108],\n         [116, 104, 102],\n         [114, 102, 100]]],\n\n\n       [[[  5,   6,   4],\n         [  5,   6,   5],\n         [  6,   6,   5],\n         ..., \n         [ 12,  14,   6],\n         [ 14,  12,   8],\n         [ 12,  15,  14]],\n\n        [[  5,   6,   5],\n         [  5,   6,   5],\n         [  6,   7,   5],\n         ..., \n         [  8,  10,   7],\n         [  5,  11,   9],\n         [  5,  14,  11]],\n\n        [[  4,   6,   5],\n         [  4,   5,   5],\n         [  5,   6,   5],\n         ..., \n         [  9,  12,   8],\n         [  9,  13,   8],\n         [ 10,  13,   9]],\n\n        ..., \n        [[100,  83,  67],\n         [ 95,  82,  71],\n         [ 97,  85,  73],\n         ..., \n         [154, 147, 109],\n         [154, 146, 104],\n         [153, 145, 102]],\n\n        [[124,  90,  75],\n         [148,  91,  75],\n         [147, 110,  74],\n         ..., \n         [167, 164, 134],\n         [161, 163, 116],\n         [160, 156, 113]],\n\n        [[146,  94,  73],\n         [168, 102,  72],\n         [149, 118,  69],\n         ..., \n         [183, 158, 117],\n         [181, 156, 117],\n         [178, 154, 114]]],\n\n\n       [[[ 19,  19,  23],\n         [ 17,  18,  21],\n         [ 16,  18,  23],\n         ..., \n         [ 14,  11,  13],\n         [ 15,  10,  12],\n         [ 15,  10,  11]],\n\n        [[ 20,  21,  25],\n         [ 21,  20,  26],\n         [ 20,  19,  28],\n         ..., \n         [ 14,  10,   8],\n         [ 15,  11,   8],\n         [ 16,  11,   9]],\n\n        [[ 19,  23,  37],\n         [ 23,  23,  37],\n         [ 30,  24,  36],\n         ..., \n         [ 14,  11,  10],\n         [ 16,  11,  11],\n         [ 17,   9,  10]],\n\n        ..., \n        [[ 47,  91,  86],\n         [ 25,  66,  62],\n         [ 31,  41,  31],\n         ..., \n         [ 20,  21,  21],\n         [ 20,  22,  23],\n         [ 21,  22,  24]],\n\n        [[ 42,  84,  87],\n         [ 26,  59,  56],\n         [ 30,  37,  30],\n         ..., \n         [ 16,  20,  21],\n         [ 15,  22,  22],\n         [ 16,  23,  24]],\n\n        [[ 37,  74,  54],\n         [ 27,  48,  40],\n         [ 29,  31,  31],\n         ..., \n         [ 17,  19,  18],\n         [ 16,  20,  19],\n         [ 16,  22,  23]]],\n\n\n       ..., \n       [[[255, 255, 255],\n         [255, 255, 255],\n         [255, 255, 255],\n         ..., \n         [ 27,  32,  32],\n         [ 33,  40,  30],\n         [ 37,  37,  22]],\n\n        [[255, 255, 255],\n         [255, 255, 255],\n         [255, 255, 255],\n         ..., \n         [ 39,  55,  29],\n         [ 49,  51,  26],\n         [ 49,  35,  19]],\n\n        [[255, 255, 255],\n         [255, 255, 255],\n         [255, 255, 255],\n         ..., \n         [ 45,  56,  27],\n         [ 47,  49,  24],\n         [ 46,  39,  16]],\n\n        ..., \n        [[ 11,  12,  14],\n         [ 12,  12,  14],\n         [ 12,  12,  15],\n         ..., \n         [ 63,  59,  55],\n         [ 63,  60,  56],\n         [ 66,  62,  54]],\n\n        [[ 12,  13,  14],\n         [ 13,  12,  14],\n         [ 13,  12,  15],\n         ..., \n         [ 62,  60,  59],\n         [ 62,  63,  64],\n         [ 67,  67,  64]],\n\n        [[ 13,  11,  14],\n         [ 14,  11,  14],\n         [ 13,  11,  14],\n         ..., \n         [ 60,  63,  63],\n         [ 60,  67,  65],\n         [ 67,  70,  65]]],\n\n\n       [[[157, 254, 255],\n         [156, 254, 255],\n         [155, 255, 255],\n         ..., \n         [ 32,  27,  11],\n         [ 47,  29,  11],\n         [ 49,  26,  11]],\n\n        [[158, 255, 255],\n         [158, 255, 255],\n         [155, 255, 255],\n         ..., \n         [ 37,  34,  13],\n         [ 56,  34,  13],\n         [ 54,  26,  14]],\n\n        [[146, 236, 255],\n         [146, 239, 255],\n         [154, 240, 255],\n         ..., \n         [ 34,  29,  13],\n         [ 43,  31,  14],\n         [ 38,  26,  16]],\n\n        ..., \n        [[241, 228, 178],\n         [228, 232, 173],\n         [230, 222, 167],\n         ..., \n         [  5,   5,   5],\n         [  5,   5,   6],\n         [  3,   4,   6]],\n\n        [[250, 241, 182],\n         [254, 245, 181],\n         [251, 241, 175],\n         ..., \n         [  4,   4,   6],\n         [  5,   3,   5],\n         [  4,   4,   5]],\n\n        [[255, 226, 165],\n         [255, 221, 155],\n         [246, 214, 141],\n         ..., \n         [  4,   5,   6],\n         [  4,   4,   5],\n         [  4,   3,   5]]],\n\n\n       [[[ 75, 158, 155],\n         [ 90, 176, 202],\n         [113, 152, 223],\n         ..., \n         [114, 171, 248],\n         [114, 171, 249],\n         [113, 171, 251]],\n\n        [[ 62,  53,  60],\n         [ 55,  81,  89],\n         [108, 115, 102],\n         ..., \n         [114, 171, 248],\n         [111, 171, 247],\n         [111, 171, 245]],\n\n        [[ 71,  41,  52],\n         [ 71,  50,  61],\n         [ 68,  94,  51],\n         ..., \n         [115, 171, 247],\n         [114, 172, 245],\n         [115, 173, 240]],\n\n        ..., \n        [[ 83,  88,  90],\n         [ 86,  91,  89],\n         [ 86,  90,  83],\n         ..., \n         [ 95,  90,  96],\n         [ 94,  90,  97],\n         [ 90,  91,  98]],\n\n        [[ 82,  90,  97],\n         [ 83,  93,  91],\n         [ 82,  88,  81],\n         ..., \n         [ 96,  86,  88],\n         [ 96,  87,  88],\n         [ 92,  86,  88]],\n\n        [[ 82,  85,  93],\n         [ 82,  84,  91],\n         [ 82,  80,  88],\n         ..., \n         [ 96,  89,  89],\n         [ 96,  91,  89],\n         [ 92,  90,  89]]]], dtype=uint8)]. All inputs to the layer should be tensors."
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(None, None, 3))\n",
    "model = InceptionV3(weights='imagenet', include_top=False, input_tensor=inputs)\n",
    "x = model.output\n",
    "\n",
    "x = Conv2D(filters=3, kernel_size=(1, 1))(X)\n",
    "x = Conv2DTranspose(filters=2, \n",
    "                        kernel_size=(64, 64),\n",
    "                        strides=(32, 32),\n",
    "                        padding='same',\n",
    "                        activation='sigmoid')(x)\n",
    "predictions = Dense(2, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=x)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X  = []\n",
    "\n",
    "images = glob.glob(\"./data/data_road/training/image_2/*.png\")\n",
    "\n",
    "for image in images:\n",
    "    img = skimage.io.imread(image)\n",
    "    img = img[0:370,0:1226, 0:3]\n",
    "    X.append(img)\n",
    "\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = []\n",
    "\n",
    "masks = glob.glob(\"./data/data_road/training/gt_image_2/*.png\")\n",
    "\n",
    "for mask in masks:\n",
    "    img = skimage.io.imread(image)\n",
    "    img = img[0:370,0:1226, 0:3]\n",
    "    \n",
    "    y.append(img)\n",
    "    \n",
    "y = np.array(y)\n",
    "y = y[:289]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(289, 370, 1226, 3)\n",
      "(289, 370, 1226, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bilinear_upsample_weights(factor, number_of_classes):\n",
    "    filter_size = factor*2 - factor%2\n",
    "    factor = (filter_size + 1) // 2\n",
    "    if filter_size % 2 == 1:\n",
    "        center = factor - 1\n",
    "    else:\n",
    "        center = factor - 0.5\n",
    "    og = np.ogrid[:filter_size, :filter_size]\n",
    "    upsample_kernel = (1 - abs(og[0] - center) / factor) * (1 - abs(og[1] - center) / factor)\n",
    "    weights = np.zeros((filter_size, filter_size, number_of_classes, number_of_classes),\n",
    "                       dtype=np.float32)\n",
    "    for i in range(number_of_classes):\n",
    "        weights[:, :, i, i] = upsample_kernel\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fcn_32s():\n",
    "    inputs = Input(shape=(None, None, 3))\n",
    "    vgg16 = VGG16(weights='imagenet', include_top=False, input_tensor=inputs)\n",
    "\n",
    "    x = Conv2D(filters=3, \n",
    "               kernel_size=(1, 1))(vgg16.output)\n",
    "    x = Conv2DTranspose(filters=3, \n",
    "                        kernel_size=(64, 64),\n",
    "                        strides=(32, 32),\n",
    "                        padding='same',\n",
    "                        activation='sigmoid',\n",
    "                        kernel_initializer=Constant(bilinear_upsample_weights(32, nb_classes)))(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "    model.summary()\n",
    "\n",
    "    for layer in model.layers[:15]:\n",
    "        layer.trainable = False\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_image(path):\n",
    "    img_org = Image.open(path)\n",
    "    w, h = img_org.size\n",
    "    img = img_org.resize(((w//1242)*1242, (h//375)*375))\n",
    "    img = np.array(img, dtype=np.float32)\n",
    "    x = np.expand_dims(img, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_label(path):\n",
    "    img_org = Image.open(path)\n",
    "    w, h = img_org.size\n",
    "    img = img_org.resize(((w//1242)*1242, (h//375)*375))\n",
    "    img = np.array(img, dtype=np.uint8)\n",
    "    img[img==255] = 0\n",
    "    y = np.zeros((1, img.shape[0], img.shape[1], nb_classes), dtype=np.float32)\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            y[0, i, j, img[i][j]] = 1\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_arrays_from_file(path, image_dir, label_dir):\n",
    "    while 1:\n",
    "        f = open(path)\n",
    "        print(f)\n",
    "        for line in f:\n",
    "            filename = line.rstrip('\\n')\n",
    "            path_image = os.path.join(image_dir, filename+'.png')\n",
    "            path_label = os.path.join(label_dir, filename+'.png')\n",
    "            x = load_image(path_image)\n",
    "            y = load_label(path_label)\n",
    "            yield (x, y)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_predict(model, input_path, output_path):\n",
    "    img_org = Image.open(input_path)\n",
    "    w, h = img_org.size\n",
    "    img = img_org.resize(((w//32)*32, (h//32)*32))\n",
    "    img = np.array(img, dtype=np.float32)\n",
    "    x = np.expand_dims(img, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    pred = model.predict(x)\n",
    "    pred = pred[0].argmax(axis=-1).astype(np.uint8)\n",
    "    img = Image.fromarray(pred, mode='P')\n",
    "    img = img.resize((w, h))\n",
    "    palette_im = Image.open('palette.png')\n",
    "    img.palette = copy.copy(palette_im.palette)\n",
    "    img.save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root_dir = 'data/data_road/training'\n",
    "img_path = 'image_2'\n",
    "mask = 'gt_image_2'\n",
    "imgs = []\n",
    "masks = []\n",
    "\n",
    "img_paths = glob.glob(os.path.join(root_dir, img_path, '*.png'))\n",
    "mask_paths = glob.glob(os.path.join(root_dir, mask, '*.png'))\n",
    "\n",
    "for img_path in img_paths:\n",
    "    img = io.imread(img_path)\n",
    "    img = np.array(img)\n",
    "    imgs.append(img)\n",
    "    \n",
    "for mask_path in mask_paths:\n",
    "    mask = io.imread(mask_path)\n",
    "    masks.append(mask)\n",
    "\n",
    "X = np.array(imgs, dtype='object')\n",
    "y = np.array(masks, dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(289,)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_data = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, None, None, 3)     1539      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, None, None, 3)     36867     \n",
      "=================================================================\n",
      "Total params: 14,753,094\n",
      "Trainable params: 14,753,094\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = fcn_32s()\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "filepath=\"weights{epoch:02d}-{loss:.4f}.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 231 samples, validate on 58 samples\n",
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "model.fit(X, y,\n",
    "          batch_size=4,\n",
    "          epochs=5,\n",
    "          validation_split=0.2,\n",
    "          callbacks=callbacks_list\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
